{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Modeling\n",
    "\n",
    "1. 머신러닝의 분야\n",
    "    - supervised\n",
    "    - unsupervised\n",
    "    - reinforcement\n",
    "    \n",
    "    ; 결국 내가 풀려는 문제가 뭔지, 어떤 방식이 가장 적절한지를 잘 파악하자.\n",
    "   \n",
    "\n",
    "2. prodedure of analyzing data, 그 중 modeling\n",
    "\n",
    "# Bias and Variance trade off\n",
    "\n",
    "1. Bias는 예측값이 실제 signal로부터 얼마나 떨어져있는지를 의미한다.\n",
    "\n",
    "2. Variance는 여러 데이터에 대해 모델이 얼마나 일관성 있게 결과를 내어놓는지를 의미한다.\n",
    "\n",
    "3. 차수가 올라갈수록 대체로 bias는 감소하고 Variance는 증가한다.\n",
    "\n",
    "$$MSE = Cost = {bias}^2 + Var$$\n",
    "\n",
    "# Overfitting과 underfitting\n",
    "\n",
    "적절한 signal을 잘 찾아보자~\n",
    "\n",
    "### Data Generating process?\n",
    "\n",
    ": 지금 내가 보고있는 이 데이터가 어떻게 나온걸까?\n",
    ": signal + noise, 즉 확률적이다\n",
    "\n",
    "# non-parametric model\n",
    ": 정해진 parameter로 압축해서 전달 > 일종의 제한일수도\n",
    ": 보통 예측력과 설명 교환\n",
    "\n",
    "1. Parametric Model\n",
    "    : 변수가 많아지면(제한 완화) 설명 불가  \n",
    "    : 직접 찾을 수 있으면 좋음. feature engineering 노가다 많이 필요\n",
    "    \n",
    "2. nonparametric model\n",
    "\n",
    "    - Highly flexible model that better performances can be achieved.\n",
    "    - Requires too much computation along with the size of data.\n",
    "    - Generally, more difficult to distinguish the effects of the variables than the parametric model.\n",
    "    - Need to tune hyperparameter in some models, such as KNN.\n",
    "\n",
    "\n",
    "예측과 인과추론? 둘 다 중요하다  \n",
    "\n",
    "## kernel smoothing?\n",
    "\n",
    "parameter가 아닌 데이터 자체를 사용해서 예측  \n",
    "; 데이터 수가 많아지면 당연히 시간 엄청 길어짐\n",
    "\n",
    "두 점 사이의 거리가 멀수록 가중치가 지수적으로 감소\n",
    "\n",
    "## K nearest neighborhood\n",
    "\n",
    "# k-fold cross validation\n",
    ": 이걸 통해서 최적의 hyper parameter 찾기\n",
    "\n",
    "# LOOCV\n",
    ": 데이터 하나하나가 fold가 된다 > 당연히 크면 못 씀\n",
    "\n",
    "# 파라미터에 대한 grid vs random search\n",
    ": 보통 random search가 더 낫다고 하기는함\n",
    "\n",
    "# 파라미터에 대한 베이지안 optimization\n",
    ": 임의의 지점에서 출발, 베이지안 추론으로 새로운 지점 추천, 이걸 바탕으로 또 추천, 추천 ,,, 계속 돈다 ~  \n",
    ":  **autoML paradigm**\n",
    "\n",
    "정밀도와 재현율(precision/reacll)  \n",
    ": f1 score; 정밀도와 재현율의 조화평균\n",
    "\n",
    "up sampling : minor group에 대해 중복추출을 해서 비율 맞춤\n",
    "down sampling : major group을 표본 추출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
